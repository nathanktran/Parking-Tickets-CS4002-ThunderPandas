{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fd228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PARKING TICKET HOTSPOT PREDICTION ANALYSIS\n",
      "Thunder Pandas - DS 4002\n",
      "================================================================================\n",
      "\n",
      "[STEP 1] Loading and cleaning parking ticket data...\n",
      "Initial dataset shape: (506311, 16)\n",
      "Columns: ['RecordID', 'TicketNumber', 'DateIssued', 'StreetName', 'TimeIssued', 'StreetNumber', 'LicenseState', 'WaiverRequestDate', 'WaiverGrantedDate', 'AppealDate', 'AppealGrantedDate', 'ViolationDescription', 'AppealStatus', 'Location', 'LicensePlateAnon', 'WaiverStatus']\n",
      "Removed 5075 rows with missing DateIssued or StreetName\n",
      "Removed void tickets. Current shape: (493346, 16)\n",
      "Filtered to 2010 onwards. Current shape: (215843, 16)\n",
      "After removing duplicates: (215612, 16)\n",
      "\n",
      "Cleaned dataset shape: (215612, 16)\n",
      "Date range: 2010-01-01 05:00:00+00:00 to 2208-11-08 05:00:00+00:00\n",
      "\n",
      "[STEP 2] Creating temporal and street-level features...\n",
      "Created temporal features: Year, Month, Day, DayOfWeek, Hour, IsWeekend, Season\n",
      "\n",
      "[STEP 3] Aggregating ticket counts by street and date...\n",
      "Aggregated dataset shape: (80784, 8)\n",
      "Date range: 2010-01-01 00:00:00 to 2208-11-08 00:00:00\n",
      "Filtered to top 50 streets. Shape: (58727, 9)\n",
      "\n",
      "[STEP 4] Preparing features for modeling...\n",
      "Feature matrix shape: (58727, 6)\n",
      "Target variable shape: (58727,)\n",
      "Features used: ['Month', 'DayOfWeek', 'IsWeekend', 'Season_Encoded', 'StreetName_Encoded', 'AvgTicketsPerDay']\n",
      "\n",
      "[STEP 5] Building naive baseline models...\n",
      "\n",
      "[STEP 6] Training and evaluating models with time series cross-validation...\n",
      "\n",
      "--- Fold 1 ---\n",
      "Naive RMSE: 3.911, MAPE: 41.45%\n",
      "Seasonal Naive RMSE: 2.861, MAPE: 93.41%\n",
      "Poisson RMSE: 3.266, MAPE: 118.34%\n",
      "Random Forest RMSE: 2.975, MAPE: 94.70%\n",
      "\n",
      "--- Fold 2 ---\n",
      "Naive RMSE: 3.928, MAPE: 43.68%\n",
      "Seasonal Naive RMSE: 2.548, MAPE: 83.04%\n",
      "Poisson RMSE: 3.185, MAPE: 106.16%\n",
      "Random Forest RMSE: 2.631, MAPE: 82.75%\n",
      "\n",
      "--- Fold 3 ---\n",
      "Naive RMSE: 3.720, MAPE: 43.26%\n",
      "Seasonal Naive RMSE: 2.606, MAPE: 79.78%\n",
      "Poisson RMSE: 3.010, MAPE: 107.80%\n",
      "Random Forest RMSE: 2.621, MAPE: 79.34%\n",
      "\n",
      "--- Fold 4 ---\n",
      "Naive RMSE: 3.376, MAPE: 63.73%\n",
      "Seasonal Naive RMSE: 2.853, MAPE: 97.84%\n",
      "Poisson RMSE: 3.252, MAPE: 123.84%\n",
      "Random Forest RMSE: 2.877, MAPE: 97.16%\n",
      "\n",
      "--- Fold 5 ---\n",
      "Naive RMSE: 3.711, MAPE: 39.98%\n",
      "Seasonal Naive RMSE: 2.574, MAPE: 86.18%\n",
      "Poisson RMSE: 3.084, MAPE: 111.35%\n",
      "Random Forest RMSE: 2.594, MAPE: 85.77%\n",
      "\n",
      "================================================================================\n",
      "CROSS-VALIDATION RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "              Model  Avg RMSE  Std RMSE  Avg MAPE (%)  Std MAPE (%)\n",
      "    Naive Baseline  3.729374  0.198947     46.420735      8.755899\n",
      "    Seasonal Naive  2.688320  0.138833     88.047406      6.657652\n",
      "Poisson Regression  3.159484  0.098416    113.496600      6.654440\n",
      "     Random Forest  2.739498  0.155744     87.941430      6.873662\n",
      "\n",
      "--- IMPROVEMENT OVER NAIVE BASELINE ---\n",
      "Poisson Regression: 15.28% improvement in RMSE\n",
      "Random Forest: 26.54% improvement in RMSE\n",
      "\n",
      "âœ“ SUCCESS: Goal of 15% improvement achieved!\n",
      "\n",
      "[STEP 8] Training final models on full dataset...\n",
      "Final models trained successfully.\n",
      "\n",
      "[STEP 9] Generating visualizations...\n",
      "Saved: model_comparison_rmse.png\n",
      "Saved: rf_predictions_vs_actual.png\n",
      "Saved: feature_importance.png\n",
      "Saved: residual_plot.png\n",
      "\n",
      "[STEP 10] Saving results...\n",
      "Saved: model_performance_metrics.csv\n",
      "Saved: feature_importance.csv\n",
      "Saved: final_predictions.csv\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "All outputs saved to ../OUTPUT/ directory\n",
      "Review the visualizations and metrics to assess model performance.\n",
      "\n",
      "Next steps:\n",
      "1. Review OUTPUT folder for all generated figures and tables\n",
      "2. Update README.md with reproduction instructions\n",
      "3. Prepare presentation materials using these results\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parking Ticket Hotspot Prediction Analysis\n",
    "Thunder Pandas - DS 4002\n",
    "Authors: JP Meyer, Nathan Tran, Sanjay Karunamoorthy\n",
    "\n",
    "This script performs the complete analysis pipeline for predicting parking tickets\n",
    "in Charlottesville using Poisson regression and Random Forest models.\n",
    "\n",
    "Requirements:\n",
    "- pandas\n",
    "- numpy\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- seaborn\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Model imports\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PARKING TICKET HOTSPOT PREDICTION ANALYSIS\")\n",
    "print(\"Thunder Pandas - DS 4002\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD AND CLEAN DATA\n",
    "# =============================================================================\n",
    "print(\"\\n[STEP 1] Loading and cleaning parking ticket data...\")\n",
    "\n",
    "# Load the data\n",
    "# NOTE: Update this path to match your data location\n",
    "df = pd.read_csv('Parking_Tickets.csv')\n",
    "\n",
    "print(f\"Initial dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Parse datetime columns\n",
    "df['DateIssued'] = pd.to_datetime(df['DateIssued'], errors='coerce')\n",
    "df['TimeIssued'] = pd.to_datetime(df['TimeIssued'], format='%H:%M', errors='coerce').dt.time\n",
    "\n",
    "# Remove rows with missing critical information\n",
    "initial_count = len(df)\n",
    "df = df.dropna(subset=['DateIssued', 'StreetName'])\n",
    "print(f\"Removed {initial_count - len(df)} rows with missing DateIssued or StreetName\")\n",
    "\n",
    "# Standardize street names (remove extra spaces, convert to uppercase)\n",
    "df['StreetName'] = df['StreetName'].str.strip().str.upper()\n",
    "\n",
    "# Remove \"Void\" violations as they are likely administrative errors\n",
    "df = df[df['ViolationDescription'] != 'Void']\n",
    "print(f\"Removed void tickets. Current shape: {df.shape}\")\n",
    "\n",
    "# Filter to reasonable date range (2010 onwards for better data quality)\n",
    "df = df[df['DateIssued'] >= '2010-01-01']\n",
    "print(f\"Filtered to 2010 onwards. Current shape: {df.shape}\")\n",
    "df = df[df['DateIssued'] <= pd.Timestamp.now()]\n",
    "print(f\"Filtered to valid dates. Current shape: {df.shape}\")\n",
    "\n",
    "# Remove duplicate tickets\n",
    "df = df.drop_duplicates(subset=['TicketNumber'])\n",
    "print(f\"After removing duplicates: {df.shape}\")\n",
    "\n",
    "print(f\"\\nCleaned dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['DateIssued'].min()} to {df['DateIssued'].max()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: CREATE TEMPORAL AND STREET-LEVEL FEATURES\n",
    "# =============================================================================\n",
    "print(\"\\n[STEP 2] Creating temporal and street-level features...\")\n",
    "\n",
    "# Extract temporal features\n",
    "df['Year'] = df['DateIssued'].dt.year\n",
    "df['Month'] = df['DateIssued'].dt.month\n",
    "df['Day'] = df['DateIssued'].dt.day\n",
    "df['DayOfWeek'] = df['DateIssued'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df['DayName'] = df['DateIssued'].dt.day_name()\n",
    "df['Hour'] = pd.to_datetime(df['TimeIssued'].astype(str), format='%H:%M:%S', errors='coerce').dt.hour\n",
    "df['IsWeekend'] = df['DayOfWeek'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Create season feature\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "df['Season'] = df['Month'].apply(get_season)\n",
    "\n",
    "# Create date for aggregation\n",
    "df['Date'] = df['DateIssued'].dt.date\n",
    "\n",
    "print(f\"Created temporal features: Year, Month, Day, DayOfWeek, Hour, IsWeekend, Season\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: AGGREGATE DATA BY STREET AND TIME\n",
    "# =============================================================================\n",
    "print(\"\\n[STEP 3] Aggregating ticket counts by street and date...\")\n",
    "\n",
    "# Aggregate by street and date\n",
    "daily_street = df.groupby(['Date', 'StreetName']).size().reset_index(name='TicketCount')\n",
    "daily_street['Date'] = pd.to_datetime(daily_street['Date'])\n",
    "\n",
    "# Add temporal features back\n",
    "daily_street['Year'] = daily_street['Date'].dt.year\n",
    "daily_street['Month'] = daily_street['Date'].dt.month\n",
    "daily_street['DayOfWeek'] = daily_street['Date'].dt.dayofweek\n",
    "daily_street['IsWeekend'] = daily_street['DayOfWeek'].isin([5, 6]).astype(int)\n",
    "daily_street['Season'] = daily_street['Month'].apply(get_season)\n",
    "\n",
    "print(f\"Aggregated dataset shape: {daily_street.shape}\")\n",
    "print(f\"Date range: {daily_street['Date'].min()} to {daily_street['Date'].max()}\")\n",
    "\n",
    "# Calculate street-level features\n",
    "street_stats = df.groupby('StreetName').size().reset_index(name='TotalTickets')\n",
    "street_stats['AvgTicketsPerDay'] = street_stats['TotalTickets'] / \\\n",
    "    (df['Date'].max() - df['Date'].min()).days\n",
    "\n",
    "# Merge street stats\n",
    "daily_street = daily_street.merge(street_stats[['StreetName', 'AvgTicketsPerDay']],\n",
    "                                   on='StreetName', how='left')\n",
    "\n",
    "# Focus on top streets to reduce noise and improve model performance\n",
    "top_streets = street_stats.nlargest(50, 'TotalTickets')['StreetName'].tolist()\n",
    "daily_street = daily_street[daily_street['StreetName'].isin(top_streets)]\n",
    "print(f\"Filtered to top 50 streets. Shape: {daily_street.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: PREPARE FEATURES FOR MODELING\n",
    "# =============================================================================\n",
    "print(\"\\n[STEP 4] Preparing features for modeling...\")\n",
    "\n",
    "# Encode categorical variables\n",
    "le_street = LabelEncoder()\n",
    "le_season = LabelEncoder()\n",
    "\n",
    "daily_street['StreetName_Encoded'] = le_street.fit_transform(daily_street['StreetName'])\n",
    "daily_street['Season_Encoded'] = le_season.fit_transform(daily_street['Season'])\n",
    "\n",
    "# Sort by date for time series split\n",
    "daily_street = daily_street.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Select features for modeling\n",
    "feature_cols = ['Month', 'DayOfWeek', 'IsWeekend', 'Season_Encoded',\n",
    "                'StreetName_Encoded', 'AvgTicketsPerDay']\n",
    "X = daily_street[feature_cols]\n",
    "y = daily_street['TicketCount']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "print(f\"Features used: {feature_cols}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: BUILD NAIVE BASELINE MODELS\n",
    "# =============================================================================\n",
    "print(\"\\n[STEP 5] Building naive baseline models...\")\n",
    "\n",
    "def naive_forecast(y_train, y_test):\n",
    "    \"\"\"Naive baseline: predict the last observed value\"\"\"\n",
    "    predictions = np.full(len(y_test), y_train.iloc[-1])\n",
    "    return predictions\n",
    "\n",
    "def seasonal_naive_forecast(daily_street_train, daily_street_test):\n",
    "    \"\"\"Seasonal naive: predict same day of week from previous week\"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    for idx, row in daily_street_test.iterrows():\n",
    "        street = row['StreetName']\n",
    "        dow = row['DayOfWeek']\n",
    "\n",
    "        # Find the same street and day of week in training data\n",
    "        historical = daily_street_train[\n",
    "            (daily_street_train['StreetName'] == street) &\n",
    "            (daily_street_train['DayOfWeek'] == dow)\n",
    "        ]\n",
    "\n",
    "        if len(historical) > 0:\n",
    "            pred = historical['TicketCount'].mean()\n",
    "        else:\n",
    "            pred = daily_street_train['TicketCount'].mean()\n",
    "\n",
    "        predictions.append(pred)\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: TRAIN AND EVALUATE MODELS WITH TIME SERIES CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "print(\"\\n[STEP 6] Training and evaluating models with time series cross-validation...\")\n",
    "\n",
    "# Use TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Storage for results\n",
    "naive_rmse_scores = []\n",
    "naive_mape_scores = []\n",
    "seasonal_rmse_scores = []\n",
    "seasonal_mape_scores = []\n",
    "poisson_rmse_scores = []\n",
    "poisson_mape_scores = []\n",
    "rf_rmse_scores = []\n",
    "rf_mape_scores = []\n",
    "\n",
    "fold = 1\n",
    "for train_idx, test_idx in tscv.split(X):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    daily_train = daily_street.iloc[train_idx]\n",
    "    daily_test = daily_street.iloc[test_idx]\n",
    "\n",
    "    # Naive baseline\n",
    "    naive_pred = naive_forecast(y_train, y_test)\n",
    "    naive_rmse = np.sqrt(mean_squared_error(y_test, naive_pred))\n",
    "    naive_mape = mean_absolute_percentage_error(y_test, naive_pred) * 100\n",
    "    naive_rmse_scores.append(naive_rmse)\n",
    "    naive_mape_scores.append(naive_mape)\n",
    "\n",
    "    # Seasonal naive baseline\n",
    "    seasonal_pred = seasonal_naive_forecast(daily_train, daily_test)\n",
    "    seasonal_rmse = np.sqrt(mean_squared_error(y_test, seasonal_pred))\n",
    "    seasonal_mape = mean_absolute_percentage_error(y_test, seasonal_pred) * 100\n",
    "    seasonal_rmse_scores.append(seasonal_rmse)\n",
    "    seasonal_mape_scores.append(seasonal_mape)\n",
    "\n",
    "    # Poisson Regression\n",
    "    poisson_model = PoissonRegressor(max_iter=500)\n",
    "    poisson_model.fit(X_train, y_train)\n",
    "    poisson_pred = poisson_model.predict(X_test)\n",
    "    poisson_rmse = np.sqrt(mean_squared_error(y_test, poisson_pred))\n",
    "    poisson_mape = mean_absolute_percentage_error(y_test, poisson_pred) * 100\n",
    "    poisson_rmse_scores.append(poisson_rmse)\n",
    "    poisson_mape_scores.append(poisson_mape)\n",
    "\n",
    "    # Random Forest Regressor\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, max_depth=10,\n",
    "                                     min_samples_split=10, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_pred = rf_model.predict(X_test)\n",
    "    rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "    rf_mape = mean_absolute_percentage_error(y_test, rf_pred) * 100\n",
    "    rf_rmse_scores.append(rf_rmse)\n",
    "    rf_mape_scores.append(rf_mape)\n",
    "\n",
    "    print(f\"Naive RMSE: {naive_rmse:.3f}, MAPE: {naive_mape:.2f}%\")\n",
    "    print(f\"Seasonal Naive RMSE: {seasonal_rmse:.3f}, MAPE: {seasonal_mape:.2f}%\")\n",
    "    print(f\"Poisson RMSE: {poisson_rmse:.3f}, MAPE: {poisson_mape:.2f}%\")\n",
    "    print(f\"Random Forest RMSE: {rf_rmse:.3f}, MAPE: {rf_mape:.2f}%\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: SUMMARIZE RESULTS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-VALIDATION RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Naive Baseline', 'Seasonal Naive', 'Poisson Regression', 'Random Forest'],\n",
    "    'Avg RMSE': [np.mean(naive_rmse_scores), np.mean(seasonal_rmse_scores),\n",
    "                 np.mean(poisson_rmse_scores), np.mean(rf_rmse_scores)],\n",
    "    'Std RMSE': [np.std(naive_rmse_scores), np.std(seasonal_rmse_scores),\n",
    "                 np.std(poisson_rmse_scores), np.std(rf_rmse_scores)],\n",
    "    'Avg MAPE (%)': [np.mean(naive_mape_scores), np.mean(seasonal_mape_scores),\n",
    "                     np.mean(poisson_mape_scores), np.mean(rf_mape_scores)],\n",
    "    'Std MAPE (%)': [np.std(naive_mape_scores), np.std(seasonal_mape_scores),\n",
    "                     np.std(poisson_mape_scores), np.std(rf_mape_scores)]\n",
    "})\n",
    "\n",
    "print(\"\\n\", results_df.to_string(index=False))\n",
    "\n",
    "# Calculate improvement over naive baseline\n",
    "baseline_rmse = results_df.loc[0, 'Avg RMSE']\n",
    "poisson_improvement = ((baseline_rmse - results_df.loc[2, 'Avg RMSE']) / baseline_rmse) * 100\n",
    "rf_improvement = ((baseline_rmse - results_df.loc[3, 'Avg RMSE']) / baseline_rmse) * 100\n",
    "\n",
    "print(f\"\\n--- IMPROVEMENT OVER NAIVE BASELINE ---\")\n",
    "print(f\"Poisson Regression: {poisson_improvement:.2f}% improvement in RMSE\")\n",
    "print(f\"Random Forest: {rf_improvement:.2f}% improvement in RMSE\")\n",
    "\n",
    "if poisson_improvement >= 15 or rf_improvement >= 15:\n",
    "    print(f\"\\nâœ“ SUCCESS: Goal of 15% improvement achieved!\")\n",
    "else:\n",
    "    print(f\"\\nâš  Goal of 15% improvement not fully achieved. Consider feature engineering.\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 8: TRAIN FINAL MODELS ON FULL DATA\n",
    "# =============================================================================\n",
    "print(\"\\n[STEP 8] Training final models on full dataset...\")\n",
    "\n",
    "# Split into train/test (80/20)\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train_final = X.iloc[:split_idx]\n",
    "X_test_final = X.iloc[split_idx:]\n",
    "y_train_final = y.iloc[:split_idx]\n",
    "y_test_final = y.iloc[split_idx:]\n",
    "\n",
    "# Train final Poisson model\n",
    "final_poisson = PoissonRegressor(max_iter=500)\n",
    "final_poisson.fit(X_train_final, y_train_final)\n",
    "poisson_final_pred = final_poisson.predict(X_test_final)\n",
    "\n",
    "# Train final Random Forest model\n",
    "final_rf = RandomForestRegressor(n_estimators=200, max_depth=15,\n",
    "                                 min_samples_split=10, random_state=42, n_jobs=-1)\n",
    "final_rf.fit(X_train_final, y_train_final)\n",
    "rf_final_pred = final_rf.predict(X_test_final)\n",
    "\n",
    "print(\"Final models trained successfully.\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 9: GENERATE VISUALIZATIONS\n",
    "# =============================================================================\n",
    "print(\"\\n[STEP 9] Generating visualizations...\")\n",
    "\n",
    "# 1. Model Comparison Bar Chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "models = results_df['Model']\n",
    "rmse_values = results_df['Avg RMSE']\n",
    "colors = ['#d62728', '#ff7f0e', '#2ca02c', '#1f77b4']\n",
    "\n",
    "plt.bar(models, rmse_values, color=colors, alpha=0.7, edgecolor='black')\n",
    "plt.axhline(y=baseline_rmse, color='red', linestyle='--', label='Naive Baseline')\n",
    "plt.xlabel('Model', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Average RMSE', fontsize=12, fontweight='bold')\n",
    "plt.title('Model Performance Comparison (Cross-Validation)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_rmse.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: model_comparison_rmse.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2. Predictions vs Actual (Random Forest)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_final, rf_final_pred, alpha=0.5, s=20)\n",
    "plt.plot([y_test_final.min(), y_test_final.max()],\n",
    "         [y_test_final.min(), y_test_final.max()],\n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Ticket Count', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Predicted Ticket Count', fontsize=12, fontweight='bold')\n",
    "plt.title('Random Forest: Predicted vs Actual Ticket Counts', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('rf_predictions_vs_actual.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: rf_predictions_vs_actual.png\")\n",
    "plt.close()\n",
    "\n",
    "# 3. Feature Importance (Random Forest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': final_rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='steelblue')\n",
    "plt.xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "plt.title('Random Forest Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: feature_importance.png\")\n",
    "plt.close()\n",
    "\n",
    "# 4. Residual Plot\n",
    "residuals = y_test_final - rf_final_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(rf_final_pred, residuals, alpha=0.5, s=20)\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel('Predicted Ticket Count', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Residuals', fontsize=12, fontweight='bold')\n",
    "plt.title('Random Forest Residual Plot', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('residual_plot.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Saved: residual_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 10: SAVE RESULTS\n",
    "# =============================================================================\n",
    "print(\"\\n[STEP 10] Saving results...\")\n",
    "\n",
    "# Save model performance metrics\n",
    "results_df.to_csv('model_performance_metrics.csv', index=False)\n",
    "print(\"Saved: model_performance_metrics.csv\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "print(\"Saved: feature_importance.csv\")\n",
    "\n",
    "# Save final predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test_final.values,\n",
    "    'Poisson_Predicted': poisson_final_pred,\n",
    "    'RandomForest_Predicted': rf_final_pred,\n",
    "    'Poisson_Error': y_test_final.values - poisson_final_pred,\n",
    "    'RF_Error': y_test_final.values - rf_final_pred\n",
    "})\n",
    "predictions_df.to_csv('../OUTPUT/final_predictions.csv', index=False)\n",
    "print(\"Saved: final_predictions.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAll outputs saved to ../OUTPUT/ directory\")\n",
    "print(f\"Review the visualizations and metrics to assess model performance.\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"1. Review OUTPUT folder for all generated figures and tables\")\n",
    "print(f\"2. Update README.md with reproduction instructions\")\n",
    "print(f\"3. Prepare presentation materials using these results\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
